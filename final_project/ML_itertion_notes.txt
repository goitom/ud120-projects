1. started with NaiveBayes and 
features_list = ['poi',
'salary', 
'bonus', 
'total_stock_value',
'pct_email_to_poi'
]

2. then scaled the features
3. Then loosened outlier restrictions

4. Then added features
features_list = ['poi',
'salary', 
'bonus', 
'total_stock_value',
# 'exercised_stock_options',
# 'from_poi_to_this_person',
# 'from_this_person_to_poi',  
# 'shared_receipt_with_poi',
'pct_email_from_poi',
'pct_email_shared_reciept',
'pct_email_to_poi'
]

5. Then added SelectKBest

6. Then went back to hand selection of features that I think are actually more meaningful.

7. Then switched classifier to SVM.

References
==========
https://discussions.udacity.com/t/p5-understanding-features-selection/38556
https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le
https://discussions.udacity.com/t/a-question-about-the-email-features-would-love-if-there-were-a-data-dictionary-about-the-email-features/273926
http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html
http://scikit-learn.org/stable/modules/pipeline.html